# -*- coding: utf-8 -*-
"""ReceiptAgent.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fnGamgeSmIXt_T5MMC9vAsoOi8a6t8pP
"""

from google.colab import drive
drive.mount('/content/drive')

from google.colab import userdata
geminiAPI = userdata.get('GeminiAPI')

import json
from pathlib import Path
import google.generativeai as genai

# Replace with your actual API key and file path
api_key = geminiAPI
file_path = "/content/drive/MyDrive/combined_receipts.pdf"

# Configure the API key
genai.configure(api_key=api_key)

# Initialize the Gemini model
model = "models/gemini-2.5-flash"

# Define the prompt
prompt = """
Analyze the attached PDF document and extract all expense-related data in a structured format. Each expense entry should include the following fields:

Date: The transaction or expense date, in YYYY-MM-DD format if available.
Description: A brief summary of the transaction or line item.
Amount: The expense amount, formatted as a number (e.g., 125.50).

Category: Classify the expense into one of the following categories, if possible:
  - Travel
  - Meals & Entertainment
  - Office Supplies
  - Transportation
  - Utilities
  - Software/Subscriptions
  - Professional Services
  - Miscellaneous


Instructions:
- Return the output as a Json file .
- Include all relevant expenses found in the document, even across multiple pages or sections.
- If a field is missing or unclear, include it with a null value or "unknown" as appropriate.
- Ignore non-expense information such as cover pages, headers, footers, or unrelated notes.
"""

try:
    # Upload PDF file
    uploaded_file = genai.upload_file(path=file_path)

    # Generate content
    response = genai.GenerativeModel(model).generate_content([
        prompt,
        uploaded_file
    ])


    exp = json.loads(response.text)
    print(json.dumps(exp, indent=2))




except Exception as e:
    print(f"Error: {e}")

import json
import re
from pathlib import Path
import google.generativeai as genai

# Replace with your actual API key and file path
api_key = geminiAPI  # Replace with your actual key
file_path = "/content/drive/MyDrive/combined_receipts.pdf"

# Configure the API key
genai.configure(api_key=api_key)

# Initialize the Gemini model
model = "models/gemini-1.5-flash"

# Define the prompt
prompt = """
Analyze the attached PDF document and extract all expense-related data in a structured format. Each expense entry should include the following fields:

- Date: The transaction or expense date, in YYYY-MM-DD format if available.
- Description: A brief summary of the transaction or line item.
- Amount: The expense amount, formatted as a number (e.g., 125.50).
- Category: Classify the expense into one of the following categories, if possible:
  - Travel
  - Meals & Entertainment
  - Office Supplies
  - Transportation
  - Utilities
  - Software/Subscriptions
  - Professional Services
  - Miscellaneous

Instructions:
- Return the output as a **raw JSON array** (no markdown formatting, no ```json blocks).
- Include all relevant expenses found in the document, even across multiple pages or sections.
- If a field is missing or unclear, include it with a null value or "unknown" as appropriate.
- Ignore non-expense information such as cover pages, headers, footers, or unrelated notes.
"""

# Load the PDF file as bytes
pdf_bytes = Path(file_path).read_bytes()

# Prepare content for the Gemini model
contents = [
    {"text": prompt},
    {
        "inline_data": {
            "mime_type": "application/pdf",
            "data": pdf_bytes
        }
    }
]

# Generate response
try:
    response = genai.GenerativeModel(model).generate_content(contents=contents)
    raw_text = response.text.strip()

    # Remove markdown-style ```json ... ``` if present
    if raw_text.startswith("```json") or raw_text.startswith("```"):
        raw_text = re.sub(r"^```(?:json)?\s*", "", raw_text)
        raw_text = re.sub(r"\s*```$", "", raw_text)

    # Attempt to parse JSON
    try:
        parsed = json.loads(raw_text)
        print("\nParsed JSON:\n", json.dumps(parsed, indent=2))
    except json.JSONDecodeError as e:
        print("\nWarning: The response is not valid JSON.")
        print("Error:", str(e))
        # print("Raw Output:\n", raw_text)

except Exception as e:
    raise Exception(f"âŒ Error from Gemini API: {e}")

open("receipts.json","w").write(json.dumps(parsed, indent=2))

with open('receipts.json', 'r') as file:
    data = json.load(file)

data

!pip install jina

!pip install torch

from chromadb import Client
from chromadb.config import Settings
client = Client(Settings(

    persist_directory="./chroma"  # Local DB
))
collection = client.get_or_create_collection("chat_memory")
import torch
from transformers import AutoTokenizer, AutoModel
tokenizer = AutoTokenizer.from_pretrained("jinaai/jina-embeddings-v3")
embedding_model = AutoModel.from_pretrained("jinaai/jina-embeddings-v3", trust_remote_code=True)

def get_embedding(texts: list[str]) -> list[list[float]]:
    with torch.no_grad():
        inputs = tokenizer(texts, padding=True, truncation=True, return_tensors="pt")
        outputs = embedding_model(**inputs)
        embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token
        return embeddings.cpu().tolist()

# ğŸ’¾ Store message in ChromaDB
def store_message(user_id: str, message: str):
    embedding = get_embedding([message])[0]
    doc_id = f"{user_id}_{abs(hash(message))}"
    collection.add(
        documents=[message],
        embeddings=[embedding],
        ids=[doc_id],
        metadatas=[{"user_id": user_id}]
    )

def retrieve_memory(user_id: str, query: str, top_k: int = 5):
    query_embedding = get_embedding([query])[0]
    result = collection.query(
        query_embeddings=[query_embedding],
        n_results=top_k,
        where={"user_id": user_id}
    )
    return result['documents'][0] if result["documents"] else []

# ğŸ¤– Generate financial report using Gemini + memory
def generate_financial_report(user_id: str, spending_data: list):
    data_json = json.dumps(spending_data, indent=2)

    # ğŸ” Get relevant past memory
    past_insights = retrieve_memory(user_id, data_json)
    memory_context = "\n\n".join(past_insights)

    # ğŸ§  Build prompt
    prompt = f"""
You are my personal Chartered Accountant (CA). Based on the spending data I provide, analyze my financial behavior and offer practical, personalized insights and financial advice. Present your findings in a professional, clearly structured **Markdown-formatted report**.

Refer to these previous insights for better context and continuity:
Now, use this new data for updated advice:
```json
{data_json}



new_prompt = f"""You are my personal Chartered Accountant (CA). Based on the spending data I provide, analyze my financial behavior and offer practical, personalized insights and financial advice. Present your findings in a professional, clearly structured **Markdown-formatted report**.

Your output must include the following:

1. **Summary** â€“ Give a high-level overview of total spending, number of transactions, and average spend per category.
2. **Category-wise Breakdown** â€“ Group transactions by category and show:
   - Total spent per category
   - % of overall spending
   - Key items or outliers
3. **Insights** â€“ Analyze spending patterns and highlight:
   - Unusual spikes or large purchases
   - Opportunities to save or optimize
   - Budgeting tips based on behavior
4. **Recommendations** â€“ Provide actionable financial advice:
   - Expense control
   - Budget allocation by category
   - Emergency fund and savings guidance
   - Any red flags you see
5. **Presentation** â€“ The response should be clearly formatted in Markdown with:
   - Headings (`#`, `##`)
   - Bullet points
   - Code blocks (if relevant)
   - Tables (for category summaries)
"""

resp = genai.GenerativeModel(model).generate_content(new_prompt)
print(resp.text)

